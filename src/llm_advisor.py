import os
from openai import OpenAI

class LLMAdvisor:
    def __init__(self, api_key: str = None, base_url: str = None, model: str = "gpt-3.5-turbo"):
        """
        åˆå§‹åŒ– AI æŠ•èµ„é¡¾é—®
        """
        self.api_key = api_key or os.getenv("LLM_API_KEY")
        self.base_url = base_url or os.getenv("LLM_BASE_URL")
        self.model = model or os.getenv("LLM_MODEL", "gpt-3.5-turbo")
        
        self.client = None
        if self.api_key:
            self.client = OpenAI(api_key=self.api_key, base_url=self.base_url)
        else:
            print("è­¦å‘Š: æœªæ£€æµ‹åˆ° LLM_API_KEYï¼ŒAI åˆ†æåŠŸèƒ½å°†ä¸å¯ç”¨ã€‚")

    def get_analysis(self, ticker: str, price_data: dict, indicators: dict, user_profile: str = "") -> str:
        """
        å‘é€æ•°æ®ç»™ LLM è·å–ä¸€æ¬¡æ€§åˆ†ææŠ¥å‘Š
        """
        if not self.client:
            return "AI é¡¾é—®æœªå¯ç”¨ (è¯·é…ç½® API Key)"

        prompt = self._build_prompt(ticker, price_data, indicators)
        
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": self._get_system_prompt(user_profile)},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.5,
                max_tokens=800
            )
            return response.choices[0].message.content
        except Exception as e:
            return f"AI åˆ†æè¯·æ±‚å¤±è´¥: {str(e)}"

    def get_chat_response(self, messages: list, context_data: str = "", user_profile: str = "") -> str:
        """
        æµå¼å¯¹è¯æ¥å£
        """
        if not self.client:
            yield "è¯·å…ˆé…ç½® API Key æ‰èƒ½ä½¿ç”¨ AI åŠ©æ‰‹ã€‚"
            return

        # æ„å»ºåŒ…å«å®æ—¶æ•°æ®çš„ System Prompt
        system_prompt = f"""ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„æŠ•èµ„äº¤æ˜“åŠ©æ‰‹ã€‚
å½“å‰å¸‚åœºä¸Šä¸‹æ–‡æ•°æ®å¦‚ä¸‹ï¼š
{context_data}

ç”¨æˆ·çš„æ ¸å¿ƒæŠ•èµ„æ€æƒ³ä¸åŸåˆ™ï¼š
{user_profile}

ä»»åŠ¡ï¼š
1. è¯·ç»“åˆã€æœ€æ–°è¡Œæƒ…æ•°æ®ã€‘å’Œã€æœ€æ–°æ–°é—»èµ„è®¯ã€‘ï¼ˆå¦‚æœæœ‰ï¼‰è¿›è¡Œç»¼åˆåˆ†æã€‚
2. å›ç­”è¦ç®€æ´ã€å®¢è§‚ã€‚å¦‚æœæ–°é—»å¯¹è‚¡ä»·æœ‰é‡å¤§å½±å“ï¼ˆåˆ©å¥½/åˆ©ç©ºï¼‰ï¼Œè¯·åŠ¡å¿…æŒ‡å‡ºã€‚
3. å¦‚æœç”¨æˆ·é—®åŠå…·ä½“ç‚¹ä½ï¼Œè¯·å‚è€ƒä¸Šä¸‹æ–‡ä¸­çš„æ”¯æ’‘/é˜»åŠ›ä½ã€‚
4. å¿…é¡»éµå®ˆç”¨æˆ·çš„æŠ•èµ„åŸåˆ™ã€‚
"""
        
        full_messages = [{"role": "system", "content": system_prompt}] + messages

        try:
            stream = self.client.chat.completions.create(
                model=self.model,
                messages=full_messages,
                stream=True,
                temperature=0.7
            )
            for chunk in stream:
                if chunk.choices[0].delta.content:
                    yield chunk.choices[0].delta.content

        except Exception as e:
            yield f"å¯¹è¯å‡ºé”™: {str(e)}"

    def _get_system_prompt(self, user_profile: str = ""):
        base_prompt = """ä½ æ˜¯ä¸€ä½ç»éªŒä¸°å¯Œçš„é‡åŒ–äº¤æ˜“å‘˜å’ŒæŠ•èµ„é¡¾é—®ã€‚ä½ çš„ç›®æ ‡æ˜¯å¸®åŠ©ç”¨æˆ·åˆ¶å®šä¸¥æ ¼ã€ç†æ€§çš„äº¤æ˜“è®¡åˆ’ã€‚
                    
è¯·ä½ æ ¹æ®ç”¨æˆ·æä¾›çš„æŠ€æœ¯æŒ‡æ ‡ï¼Œè¾“å‡ºä¸€ä»½ç»“æ„åŒ–çš„äº¤æ˜“è®¡åˆ’ã€‚
å¿…é¡»åŒ…å«æ˜ç¡®çš„æ•°å­—ï¼ˆä»·æ ¼ï¼‰å’Œé€»è¾‘ï¼ˆç†ç”±ï¼‰ã€‚æ‹’ç»æ¨¡æ£±ä¸¤å¯çš„å»ºè®®ã€‚
"""
        if user_profile:
            base_prompt += f"\nã€ç‰¹åˆ«æ³¨æ„ã€‘å¿…é¡»éµå¾ªä»¥ä¸‹ç”¨æˆ·çš„æ ¸å¿ƒæŠ•èµ„åŸåˆ™ï¼š\n{user_profile}\nå¦‚æœå¸‚åœºæƒ…å†µè¿åè¿™äº›åŸåˆ™ï¼Œè¯·æ˜ç¡®æŒ‡å‡ºå¹¶å»ºè®®æ”¾å¼ƒäº¤æ˜“ã€‚\n"

        base_prompt += """
è¾“å‡ºæ ¼å¼è¦æ±‚å¦‚ä¸‹ï¼š

### ğŸ“Š å¸‚åœºçŠ¶æ€åˆ†æ
(ç®€è¿°å½“å‰è¶‹åŠ¿ã€å¼ºå¼±çŠ¶æ€ï¼Œä»¥åŠæ”¯æ’‘/é˜»åŠ›ä½çš„æœ‰æ•ˆæ€§)

### ğŸ¯ äº¤æ˜“è®¡åˆ’ (Trading Plan)
| åŠ¨ä½œ | å»ºè®®ä»·æ ¼/åŒºé—´ | é€»è¾‘ç†ç”± |
| :--- | :--- | :--- |
| **ä¹°å…¥ (Entry)** | $XXX.XX | (ä¾‹å¦‚ï¼šå›è¸©æ”¯æ’‘ä½ä¼ç¨³ / çªç ´é˜»åŠ›ä½) |
| **æ­¢æŸ (Stop Loss)** | $XXX.XX | (ä¾‹å¦‚ï¼šè·Œç ´ ATR æ”¯æ’‘ / å…³é”®å‡çº¿å¤±æ•ˆ) |
| **æ­¢ç›ˆ (Take Profit)** | $XXX.XX | (ä¾‹å¦‚ï¼šè§¦åŠä¸Šæ–¹é˜»åŠ›ä½ / RSI è¶…ä¹°åŒºåŸŸ) |

### â±ï¸ æ—¶æœºä¸ç­–ç•¥
(æè¿°æœ€ä½³çš„å…¥åœºæ—¶æœºï¼Œä¾‹å¦‚â€œç­‰å¾…å›è°ƒä¸ç ´â€æˆ–â€œç«‹å³å¸‚ä»·å•â€ã€‚å¹¶ç»™å‡ºä»“ä½ç®¡ç†å»ºè®®ï¼Œå¦‚â€œè½»ä»“è¯•æ¢â€æˆ–â€œå³ä¾§åŠ ä»“â€)
"""
        return base_prompt

    def _build_prompt(self, ticker: str, price_data: dict, indicators: dict) -> str:
        return f"""
        è¯·åˆ†æä»¥ä¸‹è‚¡ç¥¨æ•°æ®ï¼Œå¹¶åˆ¶å®šå…·ä½“çš„äº¤æ˜“è®¡åˆ’:
        
        ã€æ ‡çš„ã€‘: {ticker}
        
        ã€æœ€æ–°è¡Œæƒ…ã€‘
        - å½“å‰ä»·æ ¼: {price_data.get('current_price', 'N/A')}
        - æ—¥æ¶¨è·Œå¹…: {price_data.get('change_percent', 'N/A')}%
        
        ã€å…³é”®æŠ€æœ¯æŒ‡æ ‡ã€‘
        - 5æ—¥å‡çº¿ (Trend): {indicators.get('sma_5', 'N/A')}
        - RSI (14) (Momentum): {indicators.get('rsi', 'N/A')}
        - è¿‘æœŸæ”¯æ’‘ä½ (Support): {indicators.get('support', 'N/A')}
        - è¿‘æœŸé˜»åŠ›ä½ (Resistance): {indicators.get('resistance', 'N/A')}
        - ATR (Volatility): {indicators.get('atr', 'N/A')}
        
        ä»»åŠ¡ï¼š
        1. åˆ¤æ–­å½“å‰è¶‹åŠ¿ï¼ˆä¸Šæ¶¨/ä¸‹è·Œ/éœ‡è¡ï¼‰ã€‚
        2. ç»“åˆæ”¯æ’‘å‹åŠ›ä½å’Œ ATRï¼Œç»™å‡ºå…·ä½“çš„ã€ä¹°å…¥ä»·ã€‘ã€ã€æ­¢æŸä»·ã€‘å’Œã€æ­¢ç›ˆä»·ã€‘ã€‚
        3. å¦‚æœå½“å‰ä¸é€‚åˆæ“ä½œï¼Œè¯·æ˜ç¡®è¯´æ˜â€œè§‚æœ›â€åŠç†ç”±ã€‚
        """
